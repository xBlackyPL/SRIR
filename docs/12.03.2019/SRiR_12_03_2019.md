# Systemy równoległe i rozproszone 

~ Wykład 12-03-2019 / Wtorek 10:30

## Middleware
Middleware stanowi podstawoą roznicę pomiedzie komputerem szeregowym a równoległym.
- Stanowi on warste softwareowa zapewniającóa zunifikowany dostęp do wszystkich wezłów systemu
- Jest też odpowiedzialny za udostępnienie zasobów zarzadzanie obciazeniem oraz informowaniem o bledach

### Pożadane cechy warstwy middleware:

- Pojedynczy punkt dostepu – czyli logujemy sie na 1 komputerze i mamy zasoby (dostęp) systemu całego
- Spojny system plików
- Ujednolicona kontrola systemu – system kolejkowy, pozwal na otrzymanie zasobów tylko wtedy keidy sa wolne
- Brak silnie wyodrębnionych podsieci - kazdywezeł moze sie równoprawnie polaczyć z innym
- Wzajemna dostepnosc pamieci – nie konczecznie dzielona tylko dostępna czy np komunikat
- System kontroli zadan - nie chcemy zostaiwc na nodzie processu który ejst urwany od rodzica
- Spojny UI dla calego systemu

MPI - messagepassing interface standardowa biblioteka.
Alternatywa:
- PVM – ma do tego sentyment
- Mechanizm gniazdek (sockety)
- HPF – Fortran
- RPC
- RMI
- CORBA

**PVM** – Parallel Virtual Machine (Egzamin) ale nie bedziemy wykorzystywać - do realizacji obliczen rozproszonych heterogenicznych I rozproszonyc. Poszczególnie komputery wchodzące w sklad Maszyny Wirtualnej mogą pracowac pod roznymi systemami. Posiada konsole oraz demony umozliwiajace wspoldzialanie programow oraz biblioteki.

**MPI** - jest to **standard**. Powstał podczas zebrania porgamistów/administratorów gdzie pogadali co potrzebuja I zaimplementowali to. Ma kilka imlementaci najbardziej popularne to MPICH (serwer wałowy) I LAM.

## Komunikacja zbiorowa

Broadcast:
`MPI_Bcast(void *buffeer, int count, MPI_Datatype datatype, int root, MPI_Comm comm)`

Synchronizatory:
`MPI_Barrier(MPI_COMM_WORLD) // synchronizator`
`MPI_Finalize() // synchronizator`

`int MPI_Scatter(voidsendbuf, int sendcnt, MPI_Datatype sendtype, void *recvbuf, int recvcnt, MPI_Datatype recvtype, int root, MPI_Comm comm)`

`int MPI_Gather(...)`

MPI_Scaterv, MPI_Gatherv -> doczytać

|przed:     | po:       |
|:----------|----------:|
| P1 - []   | P1 - [A]  | 
| P2 - [ABC]| P2 - [B]  |
| P3 - []   | P3 - [C]  |

## MPI - cheetsheet

kompilacja: `mpicc <nazwa_programu>`
uruchamianie: `mpirun -np <ilosc_procesow>  ./a.out`

**Kolejkowanie**

[Komendy](htts://task.gda.pl/material/kursy/pbs-2013/1.html)

- `qsub mpi.pbs` - wstawienie zadania do kolejki jako skrypt PBS
- `qstat` - spawdzenie statusu zadania wstawionego do kolejki
- `qdel` - usuwa zadania z kolejki
- `qalter` - zamiana parametrów zadania w kolejce
- `tracejob` 

>> end